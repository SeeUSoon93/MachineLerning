{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a9d1b2",
   "metadata": {},
   "source": [
    "### 목표\n",
    "- IMDB 영화 리뷰 데이터 The Internet Movie Database의 약자\n",
    "- 자연어 전처리 과정을 실습\n",
    "- 영화리뷰데이터를 감성분석 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492cb3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import nltk\\nnltk.download('all')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import nltk\n",
    "nltk.download('all')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45d1b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SeeUSoon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\SeeUSoon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 토큰화에 필요한 함수 호출\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# 단어 빈도 계산에 사용할 Counter()함수 호출\n",
    "from collections import Counter # 단어의 빈도수를 세어주는 함수\n",
    "from nltk.corpus import stopwords # 불용어 관련 함수\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f2f5392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Watching Time Chasers, it obvious that it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I saw this film about 20 years ago and remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Minor Spoilers In New York, Joan Barnard (Elvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I went to see this film with a great deal of e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes, I agree with everyone on this site this m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Jennifer Ehle was sparkling in \\\"Pride and Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Amy Poehler is a terrific comedian on Saturday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>A plane carrying employees of a large biotech ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>A well made, gritty science fiction movie, it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Incredibly dumb and utterly predictable story ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review\n",
       "0           0  Watching Time Chasers, it obvious that it was ...\n",
       "1           1  I saw this film about 20 years ago and remembe...\n",
       "2           2  Minor Spoilers In New York, Joan Barnard (Elvi...\n",
       "3           3  I went to see this film with a great deal of e...\n",
       "4           4  Yes, I agree with everyone on this site this m...\n",
       "5           5  Jennifer Ehle was sparkling in \\\"Pride and Pre...\n",
       "6           6  Amy Poehler is a terrific comedian on Saturday...\n",
       "7           7  A plane carrying employees of a large biotech ...\n",
       "8           8  A well made, gritty science fiction movie, it ...\n",
       "9           9  Incredibly dumb and utterly predictable story ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "# delimiter(구분자) 속성을 \\t로 지정\n",
    "df = pd.read_csv(\"imdb.tsv\", delimiter='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a43df81",
   "metadata": {},
   "source": [
    "### 대소문자 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71917d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소문자로 변화 / lower()\n",
    "df['review']=df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d0c059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>watching time chasers, it obvious that it was ...</td>\n",
       "      <td>[watching, time, chasers, ,, it, obvious, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i saw this film about 20 years ago and remembe...</td>\n",
       "      <td>[i, saw, this, film, about, 20, years, ago, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>minor spoilers in new york, joan barnard (elvi...</td>\n",
       "      <td>[minor, spoilers, in, new, york, ,, joan, barn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i went to see this film with a great deal of e...</td>\n",
       "      <td>[i, went, to, see, this, film, with, a, great,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>yes, i agree with everyone on this site this m...</td>\n",
       "      <td>[yes, ,, i, agree, with, everyone, on, this, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>jennifer ehle was sparkling in \\\"pride and pre...</td>\n",
       "      <td>[jennifer, ehle, was, sparkling, in, \\, '', pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>amy poehler is a terrific comedian on saturday...</td>\n",
       "      <td>[amy, poehler, is, a, terrific, comedian, on, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>a plane carrying employees of a large biotech ...</td>\n",
       "      <td>[a, plane, carrying, employees, of, a, large, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>a well made, gritty science fiction movie, it ...</td>\n",
       "      <td>[a, well, made, ,, gritty, science, fiction, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>incredibly dumb and utterly predictable story ...</td>\n",
       "      <td>[incredibly, dumb, and, utterly, predictable, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review  \\\n",
       "0           0  watching time chasers, it obvious that it was ...   \n",
       "1           1  i saw this film about 20 years ago and remembe...   \n",
       "2           2  minor spoilers in new york, joan barnard (elvi...   \n",
       "3           3  i went to see this film with a great deal of e...   \n",
       "4           4  yes, i agree with everyone on this site this m...   \n",
       "5           5  jennifer ehle was sparkling in \\\"pride and pre...   \n",
       "6           6  amy poehler is a terrific comedian on saturday...   \n",
       "7           7  a plane carrying employees of a large biotech ...   \n",
       "8           8  a well made, gritty science fiction movie, it ...   \n",
       "9           9  incredibly dumb and utterly predictable story ...   \n",
       "\n",
       "                                         word_tokens  \n",
       "0  [watching, time, chasers, ,, it, obvious, that...  \n",
       "1  [i, saw, this, film, about, 20, years, ago, an...  \n",
       "2  [minor, spoilers, in, new, york, ,, joan, barn...  \n",
       "3  [i, went, to, see, this, film, with, a, great,...  \n",
       "4  [yes, ,, i, agree, with, everyone, on, this, s...  \n",
       "5  [jennifer, ehle, was, sparkling, in, \\, '', pr...  \n",
       "6  [amy, poehler, is, a, terrific, comedian, on, ...  \n",
       "7  [a, plane, carrying, employees, of, a, large, ...  \n",
       "8  [a, well, made, ,, gritty, science, fiction, m...  \n",
       "9  [incredibly, dumb, and, utterly, predictable, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 코퍼스를 단어로 토큰화한 후 'word_tokens'라는 컬럼을 생성하기\n",
    "# word_tokenize 함수 사용\n",
    "# 1. df에서 review 컬럼 접근\n",
    "# 2. apply 메서드 사용해서 word_tokenize 함수 사용\n",
    "df['word_tokens']=df['review'].apply(word_tokenize)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5f068",
   "metadata": {},
   "source": [
    "### 데이터 정제\n",
    "- 등장빈도, 단어길이, 불용어 세트를 사용하여 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de409d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 모듈 파일이 중간에 수정되면 해당 내용이 자동으로 반영\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72e2f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 정의\n",
    "def plus(a,b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e50c7d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x, y)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 람다 함수 사용\n",
    "lambda x,y: x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "255a53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_set=(stopwords.words('english'))\n",
    "# 빈도수에 따른 데이터 정제 함수 : clean_by_freq\n",
    "# 단어길이에 따른 데이터 정제 함수 : clean_by_len\n",
    "# 불용어 세트를 활용한 정제 함수 : clean_by_stopwords\n",
    "\n",
    "df['cleaned_words'] = df['word_tokens'].apply(lambda x:clean_by_freq(x,1))\n",
    "df['cleaned_words'] = df['cleaned_words'].apply(lambda x:clean_by_len(x,2))\n",
    "df['cleaned_words'] = df['cleaned_words'].apply(lambda x:clean_by_stopwords(x,stopwords_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1015d82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>cleaned_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>watching time chasers, it obvious that it was ...</td>\n",
       "      <td>[watching, time, chasers, ,, it, obvious, that...</td>\n",
       "      <td>[one, film, said, '', 's, really, bad, movie, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i saw this film about 20 years ago and remembe...</td>\n",
       "      <td>[i, saw, this, film, about, 20, years, ago, an...</td>\n",
       "      <td>[film, film]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>minor spoilers in new york, joan barnard (elvi...</td>\n",
       "      <td>[minor, spoilers, in, new, york, ,, joan, barn...</td>\n",
       "      <td>[new, york, joan, barnard, elvire, audrey, bar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i went to see this film with a great deal of e...</td>\n",
       "      <td>[i, went, to, see, this, film, with, a, great,...</td>\n",
       "      <td>[went, film, film, 's, went, 's, jump, send, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>yes, i agree with everyone on this site this m...</td>\n",
       "      <td>[yes, ,, i, agree, with, everyone, on, this, s...</td>\n",
       "      <td>[site, movie, bad, even, movie, made, 's, movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>jennifer ehle was sparkling in \\\"pride and pre...</td>\n",
       "      <td>[jennifer, ehle, was, sparkling, in, \\, '', pr...</td>\n",
       "      <td>[ehle, '', '', northam, wonderful, '', '', won...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>amy poehler is a terrific comedian on saturday...</td>\n",
       "      <td>[amy, poehler, is, a, terrific, comedian, on, ...</td>\n",
       "      <td>[role, movie, n't, 's, author, book, author, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>a plane carrying employees of a large biotech ...</td>\n",
       "      <td>[a, plane, carrying, employees, of, a, large, ...</td>\n",
       "      <td>[plane, --, ceo, 's, --, search, rescue, missi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>a well made, gritty science fiction movie, it ...</td>\n",
       "      <td>[a, well, made, ,, gritty, science, fiction, m...</td>\n",
       "      <td>[gritty, movie, sci-fi, good, suspense, movie,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>incredibly dumb and utterly predictable story ...</td>\n",
       "      <td>[incredibly, dumb, and, utterly, predictable, ...</td>\n",
       "      <td>[girl, girl, '', '', --, --, '', '', '', '']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review  \\\n",
       "0           0  watching time chasers, it obvious that it was ...   \n",
       "1           1  i saw this film about 20 years ago and remembe...   \n",
       "2           2  minor spoilers in new york, joan barnard (elvi...   \n",
       "3           3  i went to see this film with a great deal of e...   \n",
       "4           4  yes, i agree with everyone on this site this m...   \n",
       "5           5  jennifer ehle was sparkling in \\\"pride and pre...   \n",
       "6           6  amy poehler is a terrific comedian on saturday...   \n",
       "7           7  a plane carrying employees of a large biotech ...   \n",
       "8           8  a well made, gritty science fiction movie, it ...   \n",
       "9           9  incredibly dumb and utterly predictable story ...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [watching, time, chasers, ,, it, obvious, that...   \n",
       "1  [i, saw, this, film, about, 20, years, ago, an...   \n",
       "2  [minor, spoilers, in, new, york, ,, joan, barn...   \n",
       "3  [i, went, to, see, this, film, with, a, great,...   \n",
       "4  [yes, ,, i, agree, with, everyone, on, this, s...   \n",
       "5  [jennifer, ehle, was, sparkling, in, \\, '', pr...   \n",
       "6  [amy, poehler, is, a, terrific, comedian, on, ...   \n",
       "7  [a, plane, carrying, employees, of, a, large, ...   \n",
       "8  [a, well, made, ,, gritty, science, fiction, m...   \n",
       "9  [incredibly, dumb, and, utterly, predictable, ...   \n",
       "\n",
       "                                       cleaned_words  \n",
       "0  [one, film, said, '', 's, really, bad, movie, ...  \n",
       "1                                       [film, film]  \n",
       "2  [new, york, joan, barnard, elvire, audrey, bar...  \n",
       "3  [went, film, film, 's, went, 's, jump, send, n...  \n",
       "4  [site, movie, bad, even, movie, made, 's, movi...  \n",
       "5  [ehle, '', '', northam, wonderful, '', '', won...  \n",
       "6  [role, movie, n't, 's, author, book, author, '...  \n",
       "7  [plane, --, ceo, 's, --, search, rescue, missi...  \n",
       "8  [gritty, movie, sci-fi, good, suspense, movie,...  \n",
       "9       [girl, girl, '', '', --, --, '', '', '', '']  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0515825",
   "metadata": {},
   "source": [
    "### 어간추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ca86cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming_by_porter 함수 적용하기\n",
    "# cleaned_words 컬럼값에 함수 적용\n",
    "df['stemmed_tokens']=df['cleaned_words'].apply(stemming_by_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6989977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장토큰화 진행\n",
    "# sent_tokenize 함수 적용\n",
    "df['sent_tokens']=df['review'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed2c6e2",
   "metadata": {},
   "source": [
    "### 품사 태깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bfa2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tagger 함수 사용하여 'sent_tokens'컬럼에 적용\n",
    "df['pos_tagged_tokens']=df['sent_tokens'].apply(pos_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef5a24",
   "metadata": {},
   "source": [
    "### 표제어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e6b5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized_tokens']= df['pos_tagged_tokens'].apply(words_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c62f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tokens']=df['lemmatized_tokens'].apply(lambda x:clean_by_freq(x,1))\n",
    "df['cleaned_tokens']=df['cleaned_tokens'].apply(lambda x:clean_by_len(x,2))\n",
    "df['cleaned_tokens']=df['cleaned_tokens'].apply(lambda x:clean_by_stopwords(x,stopwords_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b314e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>cleaned_words</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>pos_tagged_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>watching time chasers, it obvious that it was ...</td>\n",
       "      <td>[watching, time, chasers, ,, it, obvious, that...</td>\n",
       "      <td>[one, film, said, '', 's, really, bad, movie, ...</td>\n",
       "      <td>[one, film, said, '', 's, realli, bad, movi, '...</td>\n",
       "      <td>[watching time chasers, it obvious that it was...</td>\n",
       "      <td>[(watching, VBG), (time, NN), (chasers, NNS), ...</td>\n",
       "      <td>[watch, time, chaser, ,, it, obvious, that, it...</td>\n",
       "      <td>[make, one, film, say, '', 's, make, really, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i saw this film about 20 years ago and remembe...</td>\n",
       "      <td>[i, saw, this, film, about, 20, years, ago, an...</td>\n",
       "      <td>[film, film]</td>\n",
       "      <td>[film, film]</td>\n",
       "      <td>[i saw this film about 20 years ago and rememb...</td>\n",
       "      <td>[(i, NN), (saw, VBD), (this, DT), (film, NN), ...</td>\n",
       "      <td>[i, saw, this, film, about, 20, year, ago, and...</td>\n",
       "      <td>[film, film]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>minor spoilers in new york, joan barnard (elvi...</td>\n",
       "      <td>[minor, spoilers, in, new, york, ,, joan, barn...</td>\n",
       "      <td>[new, york, joan, barnard, elvire, audrey, bar...</td>\n",
       "      <td>[new, york, joan, barnard, elvir, audrey, barn...</td>\n",
       "      <td>[minor spoilers in new york, joan barnard (elv...</td>\n",
       "      <td>[(minor, JJ), (spoilers, NNS), (in, IN), (new,...</td>\n",
       "      <td>[minor, spoiler, in, new, york, ,, joan, barna...</td>\n",
       "      <td>[new, york, joan, barnard, elvire, audrey, bar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i went to see this film with a great deal of e...</td>\n",
       "      <td>[i, went, to, see, this, film, with, a, great,...</td>\n",
       "      <td>[went, film, film, 's, went, 's, jump, send, n...</td>\n",
       "      <td>[went, film, film, 's, went, 's, jump, send, n...</td>\n",
       "      <td>[i went to see this film with a great deal of ...</td>\n",
       "      <td>[(i, JJ), (went, VBD), (to, TO), (see, VB), (t...</td>\n",
       "      <td>[i, go, to, see, this, film, with, a, great, d...</td>\n",
       "      <td>[go, film, film, 's, go, 's, jump, send, n't, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>yes, i agree with everyone on this site this m...</td>\n",
       "      <td>[yes, ,, i, agree, with, everyone, on, this, s...</td>\n",
       "      <td>[site, movie, bad, even, movie, made, 's, movi...</td>\n",
       "      <td>[site, movi, bad, even, movi, made, 's, movi, ...</td>\n",
       "      <td>[yes, i agree with everyone on this site this ...</td>\n",
       "      <td>[(yes, UH), (,, ,), (i, JJ), (agree, VBP), (wi...</td>\n",
       "      <td>[yes, ,, i, agree, with, everyone, on, this, s...</td>\n",
       "      <td>[site, movie, bad, even, movie, movie, make, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>jennifer ehle was sparkling in \\\"pride and pre...</td>\n",
       "      <td>[jennifer, ehle, was, sparkling, in, \\, '', pr...</td>\n",
       "      <td>[ehle, '', '', northam, wonderful, '', '', won...</td>\n",
       "      <td>[ehl, '', '', northam, wonder, '', '', wonder,...</td>\n",
       "      <td>[jennifer ehle was sparkling in \\\"pride and pr...</td>\n",
       "      <td>[(jennifer, NN), (ehle, NN), (was, VBD), (spar...</td>\n",
       "      <td>[jennifer, ehle, be, sparkle, in, \\, '', pride...</td>\n",
       "      <td>[ehle, '', '', northam, wonderful, '', '', won...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>amy poehler is a terrific comedian on saturday...</td>\n",
       "      <td>[amy, poehler, is, a, terrific, comedian, on, ...</td>\n",
       "      <td>[role, movie, n't, 's, author, book, author, '...</td>\n",
       "      <td>[role, movi, n't, 's, author, book, author, 's...</td>\n",
       "      <td>[amy poehler is a terrific comedian on saturda...</td>\n",
       "      <td>[(amy, JJ), (poehler, NN), (is, VBZ), (a, DT),...</td>\n",
       "      <td>[amy, poehler, be, a, terrific, comedian, on, ...</td>\n",
       "      <td>[role, movie, n't, 's, author, book, funny, au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>a plane carrying employees of a large biotech ...</td>\n",
       "      <td>[a, plane, carrying, employees, of, a, large, ...</td>\n",
       "      <td>[plane, --, ceo, 's, --, search, rescue, missi...</td>\n",
       "      <td>[plane, --, ceo, 's, --, search, rescu, missio...</td>\n",
       "      <td>[a plane carrying employees of a large biotech...</td>\n",
       "      <td>[(a, DT), (plane, NN), (carrying, VBG), (emplo...</td>\n",
       "      <td>[a, plane, carry, employee, of, a, large, biot...</td>\n",
       "      <td>[plane, --, ceo, 's, --, go, search, rescue, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>a well made, gritty science fiction movie, it ...</td>\n",
       "      <td>[a, well, made, ,, gritty, science, fiction, m...</td>\n",
       "      <td>[gritty, movie, sci-fi, good, suspense, movie,...</td>\n",
       "      <td>[gritti, movi, sci-fi, good, suspens, movi, sc...</td>\n",
       "      <td>[a well made, gritty science fiction movie, it...</td>\n",
       "      <td>[(a, DT), (well, NN), (made, VBN), (,, ,), (gr...</td>\n",
       "      <td>[a, well, make, ,, gritty, science, fiction, m...</td>\n",
       "      <td>[gritty, movie, movie, keep, sci-fi, good, kee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>incredibly dumb and utterly predictable story ...</td>\n",
       "      <td>[incredibly, dumb, and, utterly, predictable, ...</td>\n",
       "      <td>[girl, girl, '', '', --, --, '', '', '', '']</td>\n",
       "      <td>[girl, girl, '', '', --, --, '', '', '', '']</td>\n",
       "      <td>[incredibly dumb and utterly predictable story...</td>\n",
       "      <td>[(incredibly, RB), (dumb, JJ), (and, CC), (utt...</td>\n",
       "      <td>[incredibly, dumb, and, utterly, predictable, ...</td>\n",
       "      <td>[girl, girl, '', '', --, --, '', '', '', '']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review  \\\n",
       "0           0  watching time chasers, it obvious that it was ...   \n",
       "1           1  i saw this film about 20 years ago and remembe...   \n",
       "2           2  minor spoilers in new york, joan barnard (elvi...   \n",
       "3           3  i went to see this film with a great deal of e...   \n",
       "4           4  yes, i agree with everyone on this site this m...   \n",
       "5           5  jennifer ehle was sparkling in \\\"pride and pre...   \n",
       "6           6  amy poehler is a terrific comedian on saturday...   \n",
       "7           7  a plane carrying employees of a large biotech ...   \n",
       "8           8  a well made, gritty science fiction movie, it ...   \n",
       "9           9  incredibly dumb and utterly predictable story ...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [watching, time, chasers, ,, it, obvious, that...   \n",
       "1  [i, saw, this, film, about, 20, years, ago, an...   \n",
       "2  [minor, spoilers, in, new, york, ,, joan, barn...   \n",
       "3  [i, went, to, see, this, film, with, a, great,...   \n",
       "4  [yes, ,, i, agree, with, everyone, on, this, s...   \n",
       "5  [jennifer, ehle, was, sparkling, in, \\, '', pr...   \n",
       "6  [amy, poehler, is, a, terrific, comedian, on, ...   \n",
       "7  [a, plane, carrying, employees, of, a, large, ...   \n",
       "8  [a, well, made, ,, gritty, science, fiction, m...   \n",
       "9  [incredibly, dumb, and, utterly, predictable, ...   \n",
       "\n",
       "                                       cleaned_words  \\\n",
       "0  [one, film, said, '', 's, really, bad, movie, ...   \n",
       "1                                       [film, film]   \n",
       "2  [new, york, joan, barnard, elvire, audrey, bar...   \n",
       "3  [went, film, film, 's, went, 's, jump, send, n...   \n",
       "4  [site, movie, bad, even, movie, made, 's, movi...   \n",
       "5  [ehle, '', '', northam, wonderful, '', '', won...   \n",
       "6  [role, movie, n't, 's, author, book, author, '...   \n",
       "7  [plane, --, ceo, 's, --, search, rescue, missi...   \n",
       "8  [gritty, movie, sci-fi, good, suspense, movie,...   \n",
       "9       [girl, girl, '', '', --, --, '', '', '', '']   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [one, film, said, '', 's, realli, bad, movi, '...   \n",
       "1                                       [film, film]   \n",
       "2  [new, york, joan, barnard, elvir, audrey, barn...   \n",
       "3  [went, film, film, 's, went, 's, jump, send, n...   \n",
       "4  [site, movi, bad, even, movi, made, 's, movi, ...   \n",
       "5  [ehl, '', '', northam, wonder, '', '', wonder,...   \n",
       "6  [role, movi, n't, 's, author, book, author, 's...   \n",
       "7  [plane, --, ceo, 's, --, search, rescu, missio...   \n",
       "8  [gritti, movi, sci-fi, good, suspens, movi, sc...   \n",
       "9       [girl, girl, '', '', --, --, '', '', '', '']   \n",
       "\n",
       "                                         sent_tokens  \\\n",
       "0  [watching time chasers, it obvious that it was...   \n",
       "1  [i saw this film about 20 years ago and rememb...   \n",
       "2  [minor spoilers in new york, joan barnard (elv...   \n",
       "3  [i went to see this film with a great deal of ...   \n",
       "4  [yes, i agree with everyone on this site this ...   \n",
       "5  [jennifer ehle was sparkling in \\\"pride and pr...   \n",
       "6  [amy poehler is a terrific comedian on saturda...   \n",
       "7  [a plane carrying employees of a large biotech...   \n",
       "8  [a well made, gritty science fiction movie, it...   \n",
       "9  [incredibly dumb and utterly predictable story...   \n",
       "\n",
       "                                   pos_tagged_tokens  \\\n",
       "0  [(watching, VBG), (time, NN), (chasers, NNS), ...   \n",
       "1  [(i, NN), (saw, VBD), (this, DT), (film, NN), ...   \n",
       "2  [(minor, JJ), (spoilers, NNS), (in, IN), (new,...   \n",
       "3  [(i, JJ), (went, VBD), (to, TO), (see, VB), (t...   \n",
       "4  [(yes, UH), (,, ,), (i, JJ), (agree, VBP), (wi...   \n",
       "5  [(jennifer, NN), (ehle, NN), (was, VBD), (spar...   \n",
       "6  [(amy, JJ), (poehler, NN), (is, VBZ), (a, DT),...   \n",
       "7  [(a, DT), (plane, NN), (carrying, VBG), (emplo...   \n",
       "8  [(a, DT), (well, NN), (made, VBN), (,, ,), (gr...   \n",
       "9  [(incredibly, RB), (dumb, JJ), (and, CC), (utt...   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  [watch, time, chaser, ,, it, obvious, that, it...   \n",
       "1  [i, saw, this, film, about, 20, year, ago, and...   \n",
       "2  [minor, spoiler, in, new, york, ,, joan, barna...   \n",
       "3  [i, go, to, see, this, film, with, a, great, d...   \n",
       "4  [yes, ,, i, agree, with, everyone, on, this, s...   \n",
       "5  [jennifer, ehle, be, sparkle, in, \\, '', pride...   \n",
       "6  [amy, poehler, be, a, terrific, comedian, on, ...   \n",
       "7  [a, plane, carry, employee, of, a, large, biot...   \n",
       "8  [a, well, make, ,, gritty, science, fiction, m...   \n",
       "9  [incredibly, dumb, and, utterly, predictable, ...   \n",
       "\n",
       "                                      cleaned_tokens  \n",
       "0  [make, one, film, say, '', 's, make, really, b...  \n",
       "1                                       [film, film]  \n",
       "2  [new, york, joan, barnard, elvire, audrey, bar...  \n",
       "3  [go, film, film, 's, go, 's, jump, send, n't, ...  \n",
       "4  [site, movie, bad, even, movie, movie, make, '...  \n",
       "5  [ehle, '', '', northam, wonderful, '', '', won...  \n",
       "6  [role, movie, n't, 's, author, book, funny, au...  \n",
       "7  [plane, --, ceo, 's, --, go, search, rescue, m...  \n",
       "8  [gritty, movie, movie, keep, sci-fi, good, kee...  \n",
       "9       [girl, girl, '', '', --, --, '', '', '', '']  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4370b5e",
   "metadata": {},
   "source": [
    "### 정수 인코딩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "907af6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['site', 'movie', 'bad', 'even', 'movie', 'movie', 'make', \"'s\", 'movie', 'special', 'describe', 'movie', 'movie', 'describe', 'movie', 'jim', 'make', 'stand-up', 'day', 'stand-up', 'jim', 'like', 'jim', 'actor', 'love', 'stand', 'day', 'comedian', 'special', 'jim', 'day', 'even', 'site', 'love', 'jim', 'stand-up', 'jim', 'actor', 'movie', 'stand', 'comedian', 'jim', 'like', \"''\", \"'s\", \"''\", \"''\", 'really', \"''\", 'terrible', 'really', 'terrible', 'movie', 'terrible', 'really', 'bad', 'movie']\n"
     ]
    }
   ],
   "source": [
    "tokens = df['cleaned_tokens'][4]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdb58197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('movie', 10), ('jim', 7), (\"''\", 4), ('stand-up', 3), ('day', 3), ('really', 3), ('terrible', 3), ('site', 2), ('bad', 2), ('even', 2), ('make', 2), (\"'s\", 2), ('special', 2), ('describe', 2), ('like', 2), ('actor', 2), ('love', 2), ('stand', 2), ('comedian', 2)]\n"
     ]
    }
   ],
   "source": [
    "vocab = Counter(tokens)\n",
    "\n",
    "# 단어 토큰들의 빈도수가 높은 순서대로 정렬\n",
    "vocab=vocab.most_common()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0b3e0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie': 1, 'jim': 2, \"''\": 3, 'stand-up': 4, 'day': 5, 'really': 6, 'terrible': 7, 'site': 8, 'bad': 9, 'even': 10, 'make': 11, \"'s\": 12, 'special': 13, 'describe': 14, 'like': 15, 'actor': 16, 'love': 17, 'stand': 18, 'comedian': 19}\n"
     ]
    }
   ],
   "source": [
    "# 각 단어에 인덱스 부여\n",
    "word_to_idx ={}\n",
    "i = 0\n",
    "\n",
    "for (word, frequency) in vocab:\n",
    "    i += 1\n",
    "    word_to_idx[word] = i\n",
    "print(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55ec38ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 1, 9, 10, 1, 1, 11, 12, 1, 13, 14, 1, 1, 14, 1, 2, 11, 4, 5, 4, 2, 15, 2, 16, 17, 18, 5, 19, 13, 2, 5, 10, 8, 17, 2, 4, 2, 16, 1, 18, 19, 2, 15, 3, 12, 3, 3, 6, 3, 7, 6, 7, 1, 7, 6, 9, 1]\n"
     ]
    }
   ],
   "source": [
    "encoded_idx = []\n",
    "\n",
    "for token in tokens:\n",
    "        idx = word_to_idx[token]\n",
    "        encoded_idx.append(idx)\n",
    "print(encoded_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c1d49a",
   "metadata": {},
   "source": [
    "### 전체 데이터 프레임 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ff80be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['make', 'one', 'film', 'say', \"''\", \"'s\", 'make', 'really', 'bad', 'movie', \"''\", 'like', 'say', 'make', 'really', 'bad', 'movie', 'bad', 'one', 'film', \"'s\", \"'s\", 'like', 'film', 'film', 'new', 'york', 'joan', 'barnard', 'elvire', 'audrey', 'barnard', 'john', 'saxon', 'italy', 'etruscan', 'tomb', 'joan', 'italy', 'colleague', 'italy', 'maggot', 'maggot', 'joan', 'drug', 'drug', 'tomb', 'colleague', 'story', 'end', 'new', 'york', 'joan', 'colleague', 'romantic', 'end', 'waste', 'time', 'watch', 'story', 'romantic', 'end', 'elvire', 'audrey', 'john', 'saxon', 'maggot', 'watch', 'etrusco', 'go', 'watch', 'go', 'go', 'waste', 'time', 'etrusco', 'etruscan', 'go', 'film', 'film', \"'s\", 'go', \"'s\", 'jump', 'send', \"n't\", 'jump', 'radio', \"n't\", 'send', 'reporter', 'fear', 'jump', 'fear', 'radio', 'reporter', \"n't\", 'radio', \"n't\", 'go', \"n't\", 'site', 'movie', 'bad', 'even', 'movie', 'movie', 'make', \"'s\", 'movie', 'special', 'describe', 'movie', 'movie', 'describe', 'movie', 'jim', 'make', 'stand-up', 'day', 'stand-up', 'jim', 'like', 'jim', 'actor', 'love', 'stand', 'day', 'comedian', 'special', 'jim', 'day', 'even', 'site', 'love', 'jim', 'stand-up', 'jim', 'actor', 'movie', 'stand', 'comedian', 'jim', 'like', \"''\", \"'s\", \"''\", \"''\", 'really', \"''\", 'terrible', 'really', 'terrible', 'movie', 'terrible', 'really', 'bad', 'movie', 'ehle', \"''\", \"''\", 'northam', 'wonderful', \"''\", \"''\", 'wonderful', 'ehle', 'northam', 'lust', 'lust', 'ehle', 'northam', 'role', 'movie', \"n't\", \"'s\", 'author', 'book', 'funny', 'author', \"'s\", 'author', 'role', \"n't\", 'funny', 'queen', 'corn', 'corn', 'queen', 'author', 'book', 'movie', \"n't\", 'plane', '--', 'ceo', \"'s\", '--', 'go', 'search', 'rescue', 'mission', 'call', 'ceo', 'harlan', 'knowles', 'lance', 'henriksen', 'put', 'search', 'rescue', 'mission', 'knowles', 'search', 'try', 'rescue', 'wood', 'film', 'one', 'lance', 'henriksen', 'one', 'two', 'could', 'easily', 'decent', 'film', 'two', \"'re\", 'quastel', \"'s\", '--', 'film', 'call', 'sasquatch', 'bad', 'edit', 'see', 'quastel', \"'s\", 'appear', \"''\", \"'s\", 'try', 'time', 'want', 'try', \"''\", 'potential', 'material', 'relate', 'plane', 'try', 'crib', 'material', 'relate', 'monster', 'crib', 'exposition', 'dialogue', 'potential', 'far', 'monster', 'costume', 'get', 'see', 'character', 'wood', 'could', 'quastel', 'would', 'stereotype', 'time', 'monster', \"'s\", \"''\", \"''\", 'edit', 'well', 'scene', 'decent', 'dialogue', 'could', 'easily', 'effective', 'sasquatch', 'make', 'reason', 'quastel', 'think', \"'s\", 'good', 'idea', 'dialogue', 'scene', 'occur', 'time', 'see', 'line', 'scene', 'line', 'scene', 'back', 'back', 'reason', 'think', \"'s\", 'good', 'idea', 'use', 'use', 'dialogue', 'whether', 'need', 'idea', 'time', 'irrelevant', 'comment', 'whether', 'irrelevant', 'comment', 'occur', 'one', 'time', 'reason', \"n't\", 'whether', 'scene', 'cut', 'random', 'scene', \"'re\", 'show', 'appear', 'random', 'important', 'either', 'never', 'appear', \"'re\", 'far', 'scene', 'reason', 'leave', 'scene', 'film', 'either', 'need', 'exposition', 'get', 'need', 'cut', \"'s\", 'important', 'monster', \"'s\", \"''\", \"''\", 'could', 'easily', 'show', 'reason', 'character', '--', '--', 'leave', 'even', 'though', \"'s\", 'reason', 'go', 'scene', 'even', 'though', 'never', 'reason', 'character', 'call', 'harlan', 'knowles', \"''\", \"''\", 'like', \"'re\", 'stereotype', 'reason', 'quastel', 'use', \"''\", \"''\", \"''\", \"''\", 'monster', 'scene', 'even', 'though', 'costume', \"n't\", 'bad', 'would', 'effective', 'put', 'bad', 'could', 'go', 'get', 'idea', 'want', 'like', 'film', 'good', \"'m\", 'henriksen', \"'m\", 'love', 'love', 'film', 'one', '--', 'could', \"n't\", 'time', 'think', \"''\", 'go', 'well', \"''\", 'quastel', 'make', 'gritty', 'movie', 'movie', 'keep', 'sci-fi', 'good', 'keep', 'suspense', 'look', 'movie', 'sci-fi', \"'re\", 'look', \"'re\", 'look', 'good', 'gritty', 'sci-fi', 'good', 'suspense', 'movie', 'good', 'girl', 'girl', \"''\", \"''\", '--', '--', \"''\", \"''\", \"''\", \"''\"]\n"
     ]
    }
   ],
   "source": [
    "# 전체 코퍼스의 토큰들을 전부 합하여 단어의 등장 빈도 계산\n",
    "print(sum(df['cleaned_tokens'],[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fae1464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"''\": 1, \"'s\": 2, 'movie': 3, 'film': 4, \"n't\": 5, 'go': 6, 'scene': 7, 'bad': 8, 'time': 9, '--': 10, 'reason': 11, 'make': 12, 'jim': 13, 'good': 14, 'one': 15, 'like': 16, 'could': 17, \"'re\": 18, 'quastel': 19, 'really': 20, 'even': 21, 'monster': 22, 'joan': 23, 'love': 24, 'author': 25, 'try': 26, 'dialogue': 27, 'idea': 28, 'italy': 29, 'colleague': 30, 'maggot': 31, 'end': 32, 'watch': 33, 'jump': 34, 'radio': 35, 'stand-up': 36, 'day': 37, 'terrible': 38, 'ehle': 39, 'northam': 40, 'search': 41, 'rescue': 42, 'call': 43, 'knowles': 44, 'henriksen': 45, 'easily': 46, 'see': 47, 'appear': 48, 'get': 49, 'character': 50, 'think': 51, 'use': 52, 'whether': 53, 'need': 54, 'though': 55, 'sci-fi': 56, 'look': 57, 'say': 58, 'new': 59, 'york': 60, 'barnard': 61, 'elvire': 62, 'audrey': 63, 'john': 64, 'saxon': 65, 'etruscan': 66, 'tomb': 67, 'drug': 68, 'story': 69, 'romantic': 70, 'waste': 71, 'etrusco': 72, 'send': 73, 'reporter': 74, 'fear': 75, 'site': 76, 'special': 77, 'describe': 78, 'actor': 79, 'stand': 80, 'comedian': 81, 'wonderful': 82, 'lust': 83, 'role': 84, 'book': 85, 'funny': 86, 'queen': 87, 'corn': 88, 'plane': 89, 'ceo': 90, 'mission': 91, 'harlan': 92, 'lance': 93, 'put': 94, 'wood': 95, 'two': 96, 'decent': 97, 'sasquatch': 98, 'edit': 99, 'want': 100, 'potential': 101, 'material': 102, 'relate': 103, 'crib': 104, 'exposition': 105, 'far': 106, 'costume': 107, 'would': 108, 'stereotype': 109, 'well': 110, 'effective': 111, 'occur': 112, 'line': 113, 'back': 114, 'irrelevant': 115, 'comment': 116, 'cut': 117, 'random': 118, 'show': 119, 'important': 120, 'either': 121, 'never': 122, 'leave': 123, \"'m\": 124, 'gritty': 125, 'keep': 126, 'suspense': 127, 'girl': 128}\n"
     ]
    }
   ],
   "source": [
    "word_to_idx = {}\n",
    "i = 0\n",
    "tokens = sum(df['cleaned_tokens'],[])\n",
    "\n",
    "vocab = Counter(tokens)\n",
    "vocab = vocab.most_common()\n",
    "\n",
    "for (word,frequency) in vocab:    \n",
    "    i += 1\n",
    "    word_to_idx[word] = i\n",
    "print(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a89b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 함수 정의\n",
    "def idx_encoder(tokens, word_to_idx):\n",
    "    encoded_idx = [] # 인코딩한 값을 담아줄 리스트\n",
    "    for token in tokens:\n",
    "        idx = word_to_idx[token]\n",
    "        encoded_idx.append(idx)\n",
    "    return encoded_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404117e",
   "metadata": {},
   "source": [
    "#### VADER 감성분석\n",
    "- 감성분석을 위한 어휘 사전이자 알고리즘\n",
    "- 축약형과 기호등을 고려하여 감성 지수를 추출\n",
    "- 소셜 미디어 텍스트를 분석할 때 자주 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5fe0a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "     ---------------------------------------- 0.0/126.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 126.0/126.0 kB 7.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\seeusoon\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\seeusoon\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\seeusoon\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\seeusoon\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\seeusoon\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2023.7.22)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0039da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 로딩\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "senti_anlyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5743c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'compound': 0.6588}\n",
      "{'neg': 0.531, 'neu': 0.469, 'pos': 0.0, 'compound': -0.5255}\n",
      "{'neg': 0.0, 'neu': 0.678, 'pos': 0.322, 'compound': 0.2263}\n"
     ]
    }
   ],
   "source": [
    "text1 = \"This is a great movie!\"\n",
    "text2 = \"This is a terrible movie!\"\n",
    "text3 = \"This movie was just okay.\"\n",
    "\n",
    "# VADER 감성분석\n",
    "# 단어, 문장, 여러 문장으로 이루어진 코퍼스도 바로 감성 지수 계산가능\n",
    "# polarity_scores 메서드 사용\n",
    "print(senti_anlyzer.polarity_scores(text1))\n",
    "print(senti_anlyzer.polarity_scores(text2))\n",
    "print(senti_anlyzer.polarity_scores(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "089ab954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching time chasers, it obvious that it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i saw this film about 20 years ago and remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minor spoilers in new york, joan barnard (elvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i went to see this film with a great deal of e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes, i agree with everyone on this site this m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jennifer ehle was sparkling in \\\"pride and pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amy poehler is a terrific comedian on saturday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a plane carrying employees of a large biotech ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a well made, gritty science fiction movie, it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>incredibly dumb and utterly predictable story ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  watching time chasers, it obvious that it was ...\n",
       "1  i saw this film about 20 years ago and remembe...\n",
       "2  minor spoilers in new york, joan barnard (elvi...\n",
       "3  i went to see this film with a great deal of e...\n",
       "4  yes, i agree with everyone on this site this m...\n",
       "5  jennifer ehle was sparkling in \\\"pride and pre...\n",
       "6  amy poehler is a terrific comedian on saturday...\n",
       "7  a plane carrying employees of a large biotech ...\n",
       "8  a well made, gritty science fiction movie, it ...\n",
       "9  incredibly dumb and utterly predictable story ..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cc5fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# varder 감성분석 함수 정의\n",
    "def vader_sentiment(text):\n",
    "    senti_anlyzer = SentimentIntensityAnalyzer()\n",
    "    #감성 분석 -polarity_scores\n",
    "    senti_score = senti_anlyzer.polarity_scores(text)['compound']\n",
    "    \n",
    "    return senti_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfd82f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching time chasers, it obvious that it was ...</td>\n",
       "      <td>-0.9095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i saw this film about 20 years ago and remembe...</td>\n",
       "      <td>-0.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minor spoilers in new york, joan barnard (elvi...</td>\n",
       "      <td>-0.2794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i went to see this film with a great deal of e...</td>\n",
       "      <td>-0.9707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes, i agree with everyone on this site this m...</td>\n",
       "      <td>0.8444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jennifer ehle was sparkling in \\\"pride and pre...</td>\n",
       "      <td>0.9494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amy poehler is a terrific comedian on saturday...</td>\n",
       "      <td>0.8473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a plane carrying employees of a large biotech ...</td>\n",
       "      <td>0.9885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a well made, gritty science fiction movie, it ...</td>\n",
       "      <td>0.9887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>incredibly dumb and utterly predictable story ...</td>\n",
       "      <td>-0.7375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  vader_sentiment\n",
       "0  watching time chasers, it obvious that it was ...          -0.9095\n",
       "1  i saw this film about 20 years ago and remembe...          -0.9694\n",
       "2  minor spoilers in new york, joan barnard (elvi...          -0.2794\n",
       "3  i went to see this film with a great deal of e...          -0.9707\n",
       "4  yes, i agree with everyone on this site this m...           0.8444\n",
       "5  jennifer ehle was sparkling in \\\"pride and pre...           0.9494\n",
       "6  amy poehler is a terrific comedian on saturday...           0.8473\n",
       "7  a plane carrying employees of a large biotech ...           0.9885\n",
       "8  a well made, gritty science fiction movie, it ...           0.9887\n",
       "9  incredibly dumb and utterly predictable story ...          -0.7375"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vader_sentiment']=df['review'].apply(vader_sentiment)\n",
    "df[['review', 'vader_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10dc1c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영화의 감성지수 총합은?\n",
    "df['vader_sentiment'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea07430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
